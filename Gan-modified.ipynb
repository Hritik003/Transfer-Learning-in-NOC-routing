{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Router:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.neighbors = [] \n",
    "        self.edges = []  \n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, start, end, length):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.length = length\n",
    "        self.load = 0  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Source_X  Source_Y  Destination_X  Destination_Y  Current_X  Current_Y  \\\n",
      "0          2         4              3              0          2          4   \n",
      "1          0         1              1              4          0          1   \n",
      "2          2         2              4              4          2          2   \n",
      "3          4         0              3              4          4          0   \n",
      "4          4         0              4              0          4          0   \n",
      "5          0         4              4              4          0          4   \n",
      "6          4         3              3              1          4          3   \n",
      "7          0         4              4              4          0          4   \n",
      "8          0         0              0              4          0          0   \n",
      "9          0         2              2              2          0          2   \n",
      "10         1         4              3              3          1          4   \n",
      "11         4         0              4              3          4          0   \n",
      "12         3         2              3              2          3          2   \n",
      "13         3         0              1              1          3          0   \n",
      "14         0         2              0              3          0          2   \n",
      "15         3         2              1              4          3          2   \n",
      "16         3         4              2              1          3          4   \n",
      "17         3         4              0              2          3          4   \n",
      "18         0         3              3              3          0          3   \n",
      "19         3         2              1              1          3          2   \n",
      "\n",
      "    Action  Next_X  Next_Y  \n",
      "0        1       2       4  \n",
      "1        1       0       1  \n",
      "2        0       2       2  \n",
      "3        0       4       0  \n",
      "4        1       4       0  \n",
      "5        0       0       4  \n",
      "6        2       4       3  \n",
      "7        1       0       4  \n",
      "8        1       0       0  \n",
      "9        0       0       2  \n",
      "10       2       1       4  \n",
      "11       2       4       0  \n",
      "12       3       3       2  \n",
      "13       0       3       0  \n",
      "14       3       0       2  \n",
      "15       0       3       2  \n",
      "16       2       3       4  \n",
      "17       0       3       4  \n",
      "18       2       0       3  \n",
      "19       2       3       2  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def generate_sample_data(m, n, num_samples):\n",
    "    data = {\n",
    "        'Source': [],\n",
    "        'Destination': [],\n",
    "        'Current_Router': [],\n",
    "        'Action': [],\n",
    "        'Next_Router': []\n",
    "    }\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        source = (random.randint(0, m-1), random.randint(0, n-1))\n",
    "        destination = (random.randint(0, m-1), random.randint(0, n-1))\n",
    "        current_router = source\n",
    "        action = random.choice(['down', 'up', 'left', 'right'])\n",
    "\n",
    "        if action == 'down' and current_router[0] < destination[0]:\n",
    "            next_router = (current_router[0] + 1, current_router[1])\n",
    "        elif action == 'up' and current_router[0] > destination[0]:\n",
    "            next_router = (current_router[0] - 1, current_router[1])\n",
    "        elif action == 'right' and current_router[1] < destination[1]:\n",
    "            next_router = (current_router[0], current_router[1] + 1)\n",
    "        elif action == 'left' and current_router[1] > destination[1]:\n",
    "            next_router = (current_router[0], current_router[1] - 1)\n",
    "        else:\n",
    "            next_router = current_router  \n",
    "\n",
    "        data['Source'].append(source)\n",
    "        data['Destination'].append(destination)\n",
    "        data['Current_Router'].append(current_router)\n",
    "        data['Action'].append(action)\n",
    "        data['Next_Router'].append(next_router)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def observation(df):\n",
    "    observations_data = {\n",
    "        'Source_X': [],\n",
    "        'Source_Y': [],\n",
    "        'Destination_X': [],\n",
    "        'Destination_Y': [],\n",
    "        'Current_X': [],\n",
    "        'Current_Y': [],\n",
    "        'Action':[],\n",
    "        'Next_X': [],\n",
    "        'Next_Y': []\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        source_x, source_y = row['Source']\n",
    "        dest_x, dest_y = row['Destination']\n",
    "        current_x, current_y = row['Current_Router']\n",
    "        action=row['Action']\n",
    "        next_x, next_y = row['Next_Router'] if row['Action'] == 'send' else (current_x, current_y)\n",
    "\n",
    "        observations_data['Source_X'].append(source_x)\n",
    "        observations_data['Source_Y'].append(source_y)\n",
    "        observations_data['Destination_X'].append(dest_x)\n",
    "        observations_data['Destination_Y'].append(dest_y)\n",
    "        observations_data['Current_X'].append(current_x)\n",
    "        observations_data['Current_Y'].append(current_y)\n",
    "        observations_data['Action'].append(action)\n",
    "        observations_data['Next_X'].append(next_x)\n",
    "        observations_data['Next_Y'].append(next_y)\n",
    "\n",
    "    return pd.DataFrame(observations_data)\n",
    "\n",
    "\n",
    "m, n = 5, 5  \n",
    "num_samples = 20\n",
    "\n",
    "sample_data = generate_sample_data(m, n, num_samples)\n",
    "\n",
    "observations_df = observation(sample_data)\n",
    "\n",
    "action_mapping = {'up': 0, 'right': 1, 'down': 2, 'left': 3}\n",
    "observations_df['Action'] = observations_df['Action'].map(action_mapping)\n",
    "\n",
    "print(observations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Current_Router</th>\n",
       "      <th>Action</th>\n",
       "      <th>Next_Router</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>(3, 0)</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>right</td>\n",
       "      <td>(2, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>right</td>\n",
       "      <td>(0, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>up</td>\n",
       "      <td>(2, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(4, 0)</td>\n",
       "      <td>(3, 4)</td>\n",
       "      <td>(4, 0)</td>\n",
       "      <td>up</td>\n",
       "      <td>(3, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(4, 0)</td>\n",
       "      <td>(4, 0)</td>\n",
       "      <td>(4, 0)</td>\n",
       "      <td>right</td>\n",
       "      <td>(4, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source Destination Current_Router Action Next_Router\n",
       "0  (2, 4)      (3, 0)         (2, 4)  right      (2, 4)\n",
       "1  (0, 1)      (1, 4)         (0, 1)  right      (0, 2)\n",
       "2  (2, 2)      (4, 4)         (2, 2)     up      (2, 2)\n",
       "3  (4, 0)      (3, 4)         (4, 0)     up      (3, 0)\n",
       "4  (4, 0)      (4, 0)         (4, 0)  right      (4, 0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Tanh()  # Assuming your data is normalized\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a dataloader for the gan from our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observations_np = observations_df.to_numpy()\n",
    "observations_tensor = torch.tensor(observations_np, dtype=torch.float64)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(observations_tensor)\n",
    "\n",
    "batch_size = 64  \n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the input noise vector\n",
    "noise_vector_size = 100  # Example size, adjust according to your generator's input layer\n",
    "\n",
    "# Generate noise based on the specified size\n",
    "noise = torch.randn(batch_size, noise_vector_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gen_optimizer, disc_optimizer, real_data_loader, epochs, device):\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for real_data in real_data_loader:\n",
    "            real_data = real_data[0].to(device)  # Assuming real_data is the first element\n",
    "            real_data = real_data.float()  # Convert real_data to float to match the discriminator's weight data type\n",
    "            batch_size = real_data.size(0)\n",
    "\n",
    "            # Zero the discriminator's gradient\n",
    "            disc_optimizer.zero_grad()\n",
    "\n",
    "            # Generate real labels\n",
    "            real_labels = torch.ones(batch_size, 1, device=device)\n",
    "\n",
    "            # Forward pass real data through discriminator\n",
    "            real_output = discriminator(real_data)\n",
    "            real_loss = criterion(real_output, real_labels)\n",
    "\n",
    "            # Generate fake data and process through discriminator\n",
    "            noise = torch.randn(batch_size, noise_vector_size, device=device)  # Use the adjusted line\n",
    "            fake_data = generator(noise)\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "            fake_output = discriminator(fake_data.detach())\n",
    "            fake_loss = criterion(fake_output, fake_labels)\n",
    "\n",
    "            # Update discriminator\n",
    "            disc_loss = real_loss + fake_loss\n",
    "            disc_loss.backward()\n",
    "            disc_optimizer.step()\n",
    "\n",
    "            # Update generator\n",
    "            gen_optimizer.zero_grad()\n",
    "            trick_labels = torch.ones(batch_size, 1, device=device)\n",
    "            trick_output = discriminator(fake_data)\n",
    "            gen_loss = criterion(trick_output, trick_labels)\n",
    "            gen_loss.backward()\n",
    "            gen_optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:  # Adjust logging frequency as needed\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss D: {disc_loss.item()}, Loss G: {gen_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "gen_input_dim = 100  \n",
    "gen_output_dim = len(observations_tensor[0])  \n",
    "disc_input_dim = gen_output_dim  \n",
    "\n",
    "\n",
    "generator = Generator(input_dim=gen_input_dim, output_dim=gen_output_dim)\n",
    "discriminator = Discriminator(input_dim=disc_input_dim)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=0.002)\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=0.002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss D: 1.3027633428573608, Loss G: 0.6584224700927734\n",
      "Epoch [11/200], Loss D: 0.9827607870101929, Loss G: 0.9108744859695435\n",
      "Epoch [21/200], Loss D: 0.5183703899383545, Loss G: 1.3145405054092407\n",
      "Epoch [31/200], Loss D: 0.10974805057048798, Loss G: 3.077634334564209\n",
      "Epoch [41/200], Loss D: 0.18329884111881256, Loss G: 4.525663375854492\n",
      "Epoch [51/200], Loss D: 0.02407725900411606, Loss G: 4.492980480194092\n",
      "Epoch [61/200], Loss D: 0.0038469904102385044, Loss G: 6.033292293548584\n",
      "Epoch [71/200], Loss D: 0.00025343368179164827, Loss G: 8.849454879760742\n",
      "Epoch [81/200], Loss D: 0.00020972291531506926, Loss G: 9.49461555480957\n",
      "Epoch [91/200], Loss D: 0.0221200343221426, Loss G: 9.249526977539062\n",
      "Epoch [101/200], Loss D: 0.0023076217621564865, Loss G: 8.721237182617188\n",
      "Epoch [111/200], Loss D: 0.0004910351126454771, Loss G: 10.333526611328125\n",
      "Epoch [121/200], Loss D: 0.00020536608644761145, Loss G: 10.64317512512207\n",
      "Epoch [131/200], Loss D: 0.11869251728057861, Loss G: 8.748391151428223\n",
      "Epoch [141/200], Loss D: 0.0027719736099243164, Loss G: 9.783069610595703\n",
      "Epoch [151/200], Loss D: 0.017842315137386322, Loss G: 7.577486991882324\n",
      "Epoch [161/200], Loss D: 0.00017918807861860842, Loss G: 9.102997779846191\n",
      "Epoch [171/200], Loss D: 0.0003378496621735394, Loss G: 9.437493324279785\n",
      "Epoch [181/200], Loss D: 0.005544479936361313, Loss G: 6.776499271392822\n",
      "Epoch [191/200], Loss D: 0.007199596613645554, Loss G: 7.011918544769287\n"
     ]
    }
   ],
   "source": [
    "epochs = 200  # Number of epochs for training\n",
    "\n",
    "train_gan(\n",
    "    generator=generator, \n",
    "    discriminator=discriminator, \n",
    "    gen_optimizer=gen_optimizer, \n",
    "    disc_optimizer=disc_optimizer, \n",
    "    real_data_loader=data_loader, \n",
    "    epochs=epochs, \n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the gan's synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.964730 -0.985407  0.988251  0.998960 -0.882355 -0.978525  0.871041   \n",
      "1  0.987782 -0.975466  0.996412  0.999611  0.382179 -0.993216  0.993199   \n",
      "2  1.000000 -1.000000  1.000000  1.000000  1.000000 -1.000000  1.000000   \n",
      "3  0.974723 -0.969872  0.988741  0.998967  0.450532 -0.987203  0.976958   \n",
      "4  1.000000 -1.000000  1.000000  1.000000  1.000000 -1.000000  1.000000   \n",
      "5  0.992475 -0.991197  0.995878  0.999962 -0.954226 -0.992383  0.963122   \n",
      "6  0.983048 -0.995304  0.996103  0.999703 -0.945527 -0.992402  0.961114   \n",
      "7  0.986123 -0.993054  0.996254  0.999778 -0.978585 -0.995627  0.950006   \n",
      "8  0.993814 -0.991044  0.993498  0.999896 -0.565986 -0.992772  0.954848   \n",
      "9  1.000000 -1.000000  1.000000  1.000000  1.000000 -1.000000  1.000000   \n",
      "\n",
      "          7         8  \n",
      "0 -0.612034  0.987279  \n",
      "1 -0.958979  0.997326  \n",
      "2 -1.000000  1.000000  \n",
      "3 -0.903850  0.997127  \n",
      "4 -1.000000  1.000000  \n",
      "5 -0.804992  0.994416  \n",
      "6 -0.661922  0.993381  \n",
      "7 -0.545405  0.995474  \n",
      "8 -0.899661  0.996038  \n",
      "9 -1.000000  1.000000  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "noise_vector_size = 100\n",
    "batch_size = 10  \n",
    "\n",
    "noise = torch.randn(batch_size, noise_vector_size, device=device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_data = generator(noise)\n",
    "    \n",
    "df_generated = pd.DataFrame(generated_data.cpu().numpy())\n",
    "print(df_generated.head(10))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Source_X  Source_Y  Destination_X  Destination_Y  Current_X  Current_Y  \\\n",
      "0         4         0              4              4          0          0   \n",
      "1         4         0              4              4          0          0   \n",
      "2         4         0              4              4          0          0   \n",
      "3         4         0              4              4          1          0   \n",
      "4         4         0              4              4          0          0   \n",
      "5         4         0              4              4          0          0   \n",
      "6         5         0              5              5          5          0   \n",
      "7         5         0              5              5          5          0   \n",
      "8         4         0              4              4          0          0   \n",
      "9         4         0              4              4          0          0   \n",
      "\n",
      "  Action  Next_X  Next_Y  \n",
      "0   left       1       4  \n",
      "1   left       0       4  \n",
      "2   left       1       4  \n",
      "3   left       0       4  \n",
      "4   left       0       4  \n",
      "5   left       1       4  \n",
      "6     up       0       5  \n",
      "7     up       0       5  \n",
      "8   left       1       4  \n",
      "9   left       1       4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Decoding function\n",
    "def decode_gan_output(gan_output, mesh_size_x, mesh_size_y):\n",
    "    decoded_data = []\n",
    "    for row in gan_output:\n",
    "        source_x = int((row[0] + 1) * mesh_size_x / 2)\n",
    "        source_y = int((row[1] + 1) * mesh_size_y / 2)\n",
    "        destination_x = int((row[2] + 1) * mesh_size_x / 2)\n",
    "        destination_y = int((row[3] + 1) * mesh_size_y / 2)\n",
    "        current_x = int((row[4] + 1) * mesh_size_x / 2)\n",
    "        current_y = int((row[5] + 1) * mesh_size_y / 2)\n",
    "        # Assuming action is discretized into 4 steps\n",
    "        action_idx = np.argmax(row[6:10])  # This part needs adjustment based on your GAN's design\n",
    "        action = ['up', 'down', 'left', 'right'][action_idx]  # Example mapping\n",
    "        next_x = int((row[7] + 1) * mesh_size_x / 2)\n",
    "        next_y = int((row[8] + 1) * mesh_size_y / 2)\n",
    "        decoded_data.append([source_x, source_y, destination_x, destination_y, current_x, current_y, action, next_x, next_y])\n",
    "    return pd.DataFrame(decoded_data, columns=['Source_X', 'Source_Y', 'Destination_X', 'Destination_Y', 'Current_X', 'Current_Y', 'Action', 'Next_X', 'Next_Y'])\n",
    "\n",
    "\n",
    "df_generated_values = df_generated.to_numpy()\n",
    "\n",
    "\n",
    "decoded_df = decode_gan_output(df_generated_values, 5, 5)\n",
    "print(decoded_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
