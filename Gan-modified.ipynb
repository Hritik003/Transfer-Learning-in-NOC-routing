{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Router:\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.neighbors = [] \n",
    "        self.edges = []  \n",
    "\n",
    "class Edge:\n",
    "    def __init__(self, start, end, length):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.length = length\n",
    "        self.load = 0  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Source_X  Source_Y  Destination_X  Destination_Y  Current_X  Current_Y  \\\n",
      "0          0         1              4              0          4          4   \n",
      "1          3         1              3              0          2          2   \n",
      "2          4         4              1              2          1          1   \n",
      "3          4         3              1              0          4          2   \n",
      "4          1         1              2              0          1          4   \n",
      "5          4         3              1              3          1          3   \n",
      "6          3         4              0              0          4          4   \n",
      "7          0         3              1              1          2          0   \n",
      "8          4         3              1              3          2          4   \n",
      "9          2         1              1              0          3          4   \n",
      "10         3         3              4              0          2          3   \n",
      "11         3         4              4              1          4          3   \n",
      "12         1         0              2              4          1          0   \n",
      "13         1         0              3              4          1          4   \n",
      "14         3         2              3              1          3          0   \n",
      "15         0         3              0              3          4          2   \n",
      "16         0         4              0              3          1          3   \n",
      "17         3         4              2              4          1          4   \n",
      "18         1         0              1              4          3          0   \n",
      "19         1         2              1              1          1          0   \n",
      "\n",
      "    Up  Right  Down  Left  Next_X  Next_Y  \n",
      "0    1      0     0     0       3       4  \n",
      "1    0      1     0     0       2       3  \n",
      "2    1      0     0     0       0       1  \n",
      "3    0      0     0     1       4       1  \n",
      "4    0      0     1     0       2       4  \n",
      "5    0      1     0     0       1       4  \n",
      "6    0      0     1     0       4       4  \n",
      "7    0      0     0     1       2       0  \n",
      "8    0      0     0     1       2       3  \n",
      "9    0      0     1     0       4       4  \n",
      "10   0      0     0     1       2       2  \n",
      "11   0      0     0     1       4       2  \n",
      "12   1      0     0     0       0       0  \n",
      "13   0      1     0     0       1       4  \n",
      "14   1      0     0     0       2       0  \n",
      "15   0      0     1     0       4       2  \n",
      "16   1      0     0     0       0       3  \n",
      "17   1      0     0     0       0       4  \n",
      "18   0      0     0     1       3       0  \n",
      "19   0      0     1     0       2       0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def generate_sample_data(m, n, num_samples):\n",
    "#     data = {\n",
    "#         'Source': [],\n",
    "#         'Destination': [],\n",
    "#         'Current_Router': [],\n",
    "#         'Action': [],\n",
    "#         'Next_Router': []\n",
    "#     }\n",
    "\n",
    "#     for _ in range(num_samples):\n",
    "#         source = (random.randint(0, m-1), random.randint(0, n-1))\n",
    "#         destination = (random.randint(0, m-1), random.randint(0, n-1))\n",
    "#         current_router = source\n",
    "#         action = random.choice(['down', 'up', 'left', 'right'])\n",
    "\n",
    "#         if action == 'down' and current_router[0] < destination[0]:\n",
    "#             next_router = (current_router[0] + 1, current_router[1])\n",
    "#         elif action == 'up' and current_router[0] > destination[0]:\n",
    "#             next_router = (current_router[0] - 1, current_router[1])\n",
    "#         elif action == 'right' and current_router[1] < destination[1]:\n",
    "#             next_router = (current_router[0], current_router[1] + 1)\n",
    "#         elif action == 'left' and current_router[1] > destination[1]:\n",
    "#             next_router = (current_router[0], current_router[1] - 1)\n",
    "#         else:\n",
    "#             next_router = current_router  \n",
    "\n",
    "#         data['Source'].append(source)\n",
    "#         data['Destination'].append(destination)\n",
    "#         data['Current_Router'].append(current_router)\n",
    "#         data['Action'].append(action)\n",
    "#         data['Next_Router'].append(next_router)\n",
    "\n",
    "#     return pd.DataFrame(data)\n",
    "def generate_sample_data(m, n, num_samples):\n",
    "    data = {\n",
    "        'Source': [],\n",
    "        'Destination': [],\n",
    "        'Current_Router': [],\n",
    "        'Up': [],\n",
    "        'Right': [],\n",
    "        'Down': [],\n",
    "        'Left': [],\n",
    "        'Next_Router': []\n",
    "    }\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        source = (random.randint(0, m-1), random.randint(0, n-1))\n",
    "        destination = (random.randint(0, m-1), random.randint(0, n-1))\n",
    "        current_router = (random.randint(0, m-1), random.randint(0, n-1))\n",
    "        action = random.choice(['down', 'up', 'left', 'right'])\n",
    "        up, down, left, right = 0, 0, 0, 0\n",
    "        if(action=='up'):up=1\n",
    "        elif(action=='down'):down=1\n",
    "        elif(action=='left'):left=1\n",
    "        elif(action=='right'):right=1\n",
    "\n",
    "\n",
    "        next_router = current_router  # Default to staying in place if action not possible\n",
    "        if down==1 and current_router[0] < m-1:\n",
    "            next_router = (current_router[0] + 1, current_router[1])\n",
    "        elif up==1 and current_router[0] > 0:\n",
    "            next_router = (current_router[0] - 1, current_router[1])\n",
    "        elif right==1 and current_router[1] < n-1:\n",
    "            next_router = (current_router[0], current_router[1] + 1)\n",
    "        elif left==1 and current_router[1] > 0:\n",
    "            next_router = (current_router[0], current_router[1] - 1)\n",
    "\n",
    "        # Add the generated data to the dictionary\n",
    "        data['Source'].append(source)\n",
    "        data['Destination'].append(destination)\n",
    "        data['Current_Router'].append(current_router)\n",
    "        data['Up'].append(up)\n",
    "        data['Down'].append(down)\n",
    "        data['Left'].append(left)\n",
    "        data['Right'].append(right)\n",
    "        data['Next_Router'].append(next_router)\n",
    "\n",
    "    # Convert the dictionary to a DataFrame and return\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def observation(df):\n",
    "    observations_data = {\n",
    "        'Source_X': [],\n",
    "        'Source_Y': [],\n",
    "        'Destination_X': [],\n",
    "        'Destination_Y': [],\n",
    "        'Current_X': [],\n",
    "        'Current_Y': [],\n",
    "        'Up': [],\n",
    "        'Right': [],\n",
    "        'Down': [],\n",
    "        'Left': [],\n",
    "        'Next_X': [],\n",
    "        'Next_Y': []\n",
    "    }\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        source_x, source_y = row['Source']\n",
    "        dest_x, dest_y = row['Destination']\n",
    "        current_x, current_y = row['Current_Router']\n",
    "        up=row['Up']\n",
    "        down=row['Down']\n",
    "        left=row['Left']\n",
    "        right=row['Right']\n",
    "        next_x, next_y = row['Next_Router'] \n",
    "\n",
    "        observations_data['Source_X'].append(source_x)\n",
    "        observations_data['Source_Y'].append(source_y)\n",
    "        observations_data['Destination_X'].append(dest_x)\n",
    "        observations_data['Destination_Y'].append(dest_y)\n",
    "        observations_data['Current_X'].append(current_x)\n",
    "        observations_data['Current_Y'].append(current_y)\n",
    "        observations_data['Up'].append(up)\n",
    "        observations_data['Down'].append(down)\n",
    "        observations_data['Left'].append(left)\n",
    "        observations_data['Right'].append(right)\n",
    "        observations_data['Next_X'].append(next_x)\n",
    "        observations_data['Next_Y'].append(next_y)\n",
    "\n",
    "    return pd.DataFrame(observations_data)\n",
    "\n",
    "\n",
    "m, n = 5, 5  \n",
    "num_samples = 20\n",
    "\n",
    "sample_data = generate_sample_data(m, n, num_samples)\n",
    "\n",
    "observations_df = observation(sample_data)\n",
    "\n",
    "# action_mapping = {'up': 0, 'right': 1, 'down': 2, 'left': 3}\n",
    "# observations_df['Action'] = observations_df['Action'].map(action_mapping)\n",
    "\n",
    "print(observations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Current_Router</th>\n",
       "      <th>Up</th>\n",
       "      <th>Right</th>\n",
       "      <th>Down</th>\n",
       "      <th>Left</th>\n",
       "      <th>Next_Router</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(4, 0)</td>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(3, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(3, 1)</td>\n",
       "      <td>(3, 0)</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(2, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(4, 4)</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(4, 3)</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>(4, 2)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(4, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>(2, 0)</td>\n",
       "      <td>(1, 4)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(2, 4)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source Destination Current_Router  Up  Right  Down  Left Next_Router\n",
       "0  (0, 1)      (4, 0)         (4, 4)   1      0     0     0      (3, 4)\n",
       "1  (3, 1)      (3, 0)         (2, 2)   0      1     0     0      (2, 3)\n",
       "2  (4, 4)      (1, 2)         (1, 1)   1      0     0     0      (0, 1)\n",
       "3  (4, 3)      (1, 0)         (4, 2)   0      0     0     1      (4, 1)\n",
       "4  (1, 1)      (2, 0)         (1, 4)   0      0     1     0      (2, 4)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.action_head = nn.Sequential(\n",
    "            nn.Linear(output_dim, 4), \n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        main_output = self.main(x)\n",
    "        action_probs = self.action_head(main_output)\n",
    "        return main_output, action_probs  \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3), \n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a dataloader for the gan from our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observations_np = observations_df.to_numpy()\n",
    "observations_tensor = torch.tensor(observations_np, dtype=torch.float64)\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(observations_tensor)\n",
    "\n",
    "batch_size = 64  \n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "noise_vector_size = 100  \n",
    "\n",
    "noise = torch.randn(batch_size, noise_vector_size, device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gen_optimizer, disc_optimizer, real_data_loader, epochs, device):\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for real_data in real_data_loader:\n",
    "            real_data = real_data[0].to(device) \n",
    "            real_data = real_data.float()\n",
    "            if real_data.shape[1] != 12:\n",
    "                raise ValueError(f'Expected {12} features, but got {real_data.shape[1]}')\n",
    "            batch_size = real_data.size(0)\n",
    "\n",
    "\n",
    "            disc_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            real_labels = torch.ones(batch_size, 1, device=device)\n",
    "\n",
    "\n",
    "            real_output = discriminator(real_data)\n",
    "            real_loss = criterion(real_output, real_labels)\n",
    "\n",
    "\n",
    "            noise = torch.randn(batch_size, noise_vector_size, device=device)  \n",
    "            fake_data, _ = generator(noise)\n",
    "            fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "            fake_output = discriminator(fake_data.detach())\n",
    "            fake_loss = criterion(fake_output, fake_labels)\n",
    "\n",
    "\n",
    "            disc_loss = real_loss + fake_loss\n",
    "            disc_loss.backward()\n",
    "            disc_optimizer.step()\n",
    "\n",
    "\n",
    "            gen_optimizer.zero_grad()\n",
    "            trick_labels = torch.ones(batch_size, 1, device=device)\n",
    "            trick_output = discriminator(fake_data)\n",
    "            gen_loss = criterion(trick_output, trick_labels)\n",
    "            gen_loss.backward()\n",
    "            gen_optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0: \n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss D: {disc_loss.item()}, Loss G: {gen_loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "noise_dim = 100\n",
    "gen_output_dim = 12\n",
    "disc_input_dim = gen_output_dim  \n",
    "\n",
    "\n",
    "generator = Generator(input_dim=noise_dim, output_dim=gen_output_dim)\n",
    "discriminator = Discriminator(input_dim=disc_input_dim)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "\n",
    "gen_optimizer = optim.Adam(generator.parameters(), lr=0.002)\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=0.002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss D: 1.4574804306030273, Loss G: 0.6436331868171692\n",
      "Epoch [11/1000], Loss D: 1.0226306915283203, Loss G: 0.7691770792007446\n",
      "Epoch [21/1000], Loss D: 0.9784233570098877, Loss G: 0.8901458978652954\n",
      "Epoch [31/1000], Loss D: 0.1612567901611328, Loss G: 2.6684887409210205\n",
      "Epoch [41/1000], Loss D: 0.05125553905963898, Loss G: 4.738255023956299\n",
      "Epoch [51/1000], Loss D: 0.024436943233013153, Loss G: 5.415875434875488\n",
      "Epoch [61/1000], Loss D: 1.0855342149734497, Loss G: 2.1304662227630615\n",
      "Epoch [71/1000], Loss D: 0.02091560885310173, Loss G: 5.183468818664551\n",
      "Epoch [81/1000], Loss D: 0.1203194260597229, Loss G: 4.935229778289795\n",
      "Epoch [91/1000], Loss D: 0.006096262019127607, Loss G: 7.385222434997559\n",
      "Epoch [101/1000], Loss D: 0.06759977340698242, Loss G: 6.984364986419678\n",
      "Epoch [111/1000], Loss D: 0.002173712942749262, Loss G: 9.563599586486816\n",
      "Epoch [121/1000], Loss D: 0.0027347782161086798, Loss G: 9.362735748291016\n",
      "Epoch [131/1000], Loss D: 0.011093508452177048, Loss G: 7.25888204574585\n",
      "Epoch [141/1000], Loss D: 0.06683023273944855, Loss G: 8.01099681854248\n",
      "Epoch [151/1000], Loss D: 0.0710902214050293, Loss G: 10.419398307800293\n",
      "Epoch [161/1000], Loss D: 0.05883248522877693, Loss G: 14.950401306152344\n",
      "Epoch [171/1000], Loss D: 0.016747476533055305, Loss G: 13.673032760620117\n",
      "Epoch [181/1000], Loss D: 0.09994076192378998, Loss G: 15.407392501831055\n",
      "Epoch [191/1000], Loss D: 0.025623654946684837, Loss G: 12.992509841918945\n",
      "Epoch [201/1000], Loss D: 0.0010111802257597446, Loss G: 12.639802932739258\n",
      "Epoch [211/1000], Loss D: 0.20893925428390503, Loss G: 7.373816013336182\n",
      "Epoch [221/1000], Loss D: 0.024906622245907784, Loss G: 5.563898086547852\n",
      "Epoch [231/1000], Loss D: 0.016051705926656723, Loss G: 7.381519317626953\n",
      "Epoch [241/1000], Loss D: 0.00751517852768302, Loss G: 7.391690254211426\n",
      "Epoch [251/1000], Loss D: 0.006754378322511911, Loss G: 6.534319877624512\n",
      "Epoch [261/1000], Loss D: 0.0042421394027769566, Loss G: 6.226738929748535\n",
      "Epoch [271/1000], Loss D: 0.003601518925279379, Loss G: 6.041605472564697\n",
      "Epoch [281/1000], Loss D: 0.0031635139603167772, Loss G: 7.032591819763184\n",
      "Epoch [291/1000], Loss D: 0.0022031343542039394, Loss G: 7.2456207275390625\n",
      "Epoch [301/1000], Loss D: 0.0011100613046437502, Loss G: 7.308560848236084\n",
      "Epoch [311/1000], Loss D: 0.0011414423352107406, Loss G: 7.4987311363220215\n",
      "Epoch [321/1000], Loss D: 0.00089789810590446, Loss G: 7.571004390716553\n",
      "Epoch [331/1000], Loss D: 0.006246642209589481, Loss G: 6.592151641845703\n",
      "Epoch [341/1000], Loss D: 0.005898684728890657, Loss G: 7.679953098297119\n",
      "Epoch [351/1000], Loss D: 0.0022479414474219084, Loss G: 7.982516288757324\n",
      "Epoch [361/1000], Loss D: 0.0015933029353618622, Loss G: 7.722159385681152\n",
      "Epoch [371/1000], Loss D: 0.0047598029486835, Loss G: 7.113119602203369\n",
      "Epoch [381/1000], Loss D: 0.008544857613742352, Loss G: 7.201228141784668\n",
      "Epoch [391/1000], Loss D: 0.0015005302848294377, Loss G: 7.241111755371094\n",
      "Epoch [401/1000], Loss D: 0.001232043607160449, Loss G: 8.147370338439941\n",
      "Epoch [411/1000], Loss D: 0.0004985879641026258, Loss G: 8.724115371704102\n",
      "Epoch [421/1000], Loss D: 0.000601506675593555, Loss G: 8.884358406066895\n",
      "Epoch [431/1000], Loss D: 0.0006382493302226067, Loss G: 8.453404426574707\n",
      "Epoch [441/1000], Loss D: 0.0022970743011683226, Loss G: 7.069035530090332\n",
      "Epoch [451/1000], Loss D: 0.0005714833969250321, Loss G: 8.971980094909668\n",
      "Epoch [461/1000], Loss D: 0.0006926607456989586, Loss G: 8.740853309631348\n",
      "Epoch [471/1000], Loss D: 0.0006108868401497602, Loss G: 8.683804512023926\n",
      "Epoch [481/1000], Loss D: 0.000990506843663752, Loss G: 7.945293426513672\n",
      "Epoch [491/1000], Loss D: 0.002564240014180541, Loss G: 8.071088790893555\n",
      "Epoch [501/1000], Loss D: 0.0033561468590050936, Loss G: 8.69805908203125\n",
      "Epoch [511/1000], Loss D: 0.00173110980540514, Loss G: 7.75133752822876\n",
      "Epoch [521/1000], Loss D: 0.001815041876398027, Loss G: 8.290550231933594\n",
      "Epoch [531/1000], Loss D: 0.0008249178645201027, Loss G: 8.25524616241455\n",
      "Epoch [541/1000], Loss D: 0.0007276481483131647, Loss G: 8.510693550109863\n",
      "Epoch [551/1000], Loss D: 0.0006705319974571466, Loss G: 9.234842300415039\n",
      "Epoch [561/1000], Loss D: 0.0006312088225968182, Loss G: 8.856614112854004\n",
      "Epoch [571/1000], Loss D: 0.0006588522810488939, Loss G: 9.125990867614746\n",
      "Epoch [581/1000], Loss D: 0.0005350100109353662, Loss G: 8.461519241333008\n",
      "Epoch [591/1000], Loss D: 0.001518517965450883, Loss G: 6.886746883392334\n",
      "Epoch [601/1000], Loss D: 0.001242638099938631, Loss G: 7.601641654968262\n",
      "Epoch [611/1000], Loss D: 0.000758809968829155, Loss G: 7.903338432312012\n",
      "Epoch [621/1000], Loss D: 0.0013178244698792696, Loss G: 8.074821472167969\n",
      "Epoch [631/1000], Loss D: 0.0006704975385218859, Loss G: 8.060226440429688\n",
      "Epoch [641/1000], Loss D: 0.0011794744059443474, Loss G: 8.053704261779785\n",
      "Epoch [651/1000], Loss D: 0.0005717761814594269, Loss G: 8.370525360107422\n",
      "Epoch [661/1000], Loss D: 0.000513034057803452, Loss G: 8.52033805847168\n",
      "Epoch [671/1000], Loss D: 0.0010898392647504807, Loss G: 8.257322311401367\n",
      "Epoch [681/1000], Loss D: 0.0005532213253900409, Loss G: 8.309242248535156\n",
      "Epoch [691/1000], Loss D: 0.00039157201535999775, Loss G: 8.690439224243164\n",
      "Epoch [701/1000], Loss D: 0.0005579126300290227, Loss G: 8.869279861450195\n",
      "Epoch [711/1000], Loss D: 0.00038214807864278555, Loss G: 8.776488304138184\n",
      "Epoch [721/1000], Loss D: 0.0003309283056296408, Loss G: 8.515402793884277\n",
      "Epoch [731/1000], Loss D: 0.0006283787661232054, Loss G: 8.700250625610352\n",
      "Epoch [741/1000], Loss D: 0.0004050017159897834, Loss G: 8.475946426391602\n",
      "Epoch [751/1000], Loss D: 0.00040036137215793133, Loss G: 8.800549507141113\n",
      "Epoch [761/1000], Loss D: 0.00043179828207939863, Loss G: 8.306509017944336\n",
      "Epoch [771/1000], Loss D: 0.00031658500665798783, Loss G: 8.655128479003906\n",
      "Epoch [781/1000], Loss D: 0.0003622035146690905, Loss G: 8.2135648727417\n",
      "Epoch [791/1000], Loss D: 0.0004629010218195617, Loss G: 8.795812606811523\n",
      "Epoch [801/1000], Loss D: 0.00026704202173277736, Loss G: 8.609704971313477\n",
      "Epoch [811/1000], Loss D: 0.000242132373386994, Loss G: 8.723382949829102\n",
      "Epoch [821/1000], Loss D: 0.000365940184565261, Loss G: 8.970907211303711\n",
      "Epoch [831/1000], Loss D: 0.00023094956122804433, Loss G: 9.209243774414062\n",
      "Epoch [841/1000], Loss D: 0.000284486886812374, Loss G: 9.082883834838867\n",
      "Epoch [851/1000], Loss D: 0.00022984347015153617, Loss G: 9.348132133483887\n",
      "Epoch [861/1000], Loss D: 0.00035776561708189547, Loss G: 8.468938827514648\n",
      "Epoch [871/1000], Loss D: 0.0005355645553208888, Loss G: 8.648635864257812\n",
      "Epoch [881/1000], Loss D: 0.0002500857226550579, Loss G: 8.5579252243042\n",
      "Epoch [891/1000], Loss D: 0.00024933076929301023, Loss G: 9.472125053405762\n",
      "Epoch [901/1000], Loss D: 0.00025091125280596316, Loss G: 9.406839370727539\n",
      "Epoch [911/1000], Loss D: 0.00033145013730973005, Loss G: 9.182217597961426\n",
      "Epoch [921/1000], Loss D: 0.00010792329703690484, Loss G: 9.594974517822266\n",
      "Epoch [931/1000], Loss D: 0.00010684260632842779, Loss G: 9.512810707092285\n",
      "Epoch [941/1000], Loss D: 7.022458157734945e-05, Loss G: 9.613767623901367\n",
      "Epoch [951/1000], Loss D: 0.00012970561510883272, Loss G: 9.885710716247559\n",
      "Epoch [961/1000], Loss D: 0.00012666903785429895, Loss G: 9.890020370483398\n",
      "Epoch [971/1000], Loss D: 8.52403391036205e-05, Loss G: 10.089717864990234\n",
      "Epoch [981/1000], Loss D: 0.00012453646922949702, Loss G: 10.012253761291504\n",
      "Epoch [991/1000], Loss D: 5.034844798501581e-05, Loss G: 9.81660270690918\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000  \n",
    "\n",
    "train_gan(\n",
    "    generator=generator, \n",
    "    discriminator=discriminator, \n",
    "    gen_optimizer=gen_optimizer, \n",
    "    disc_optimizer=disc_optimizer, \n",
    "    real_data_loader=data_loader, \n",
    "    epochs=epochs, \n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the gan's synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0  -0.930242  0.999999  0.999922  0.999997  0.999936  0.999429  0.279414   \n",
      "1   1.000000  1.000000  1.000000  1.000000  1.000000  1.000000 -0.417433   \n",
      "2  -0.918043  0.999998  0.999909  0.999994  0.999919  0.999478  0.266755   \n",
      "3   0.999417  1.000000  1.000000  1.000000  0.999999  0.999999 -0.370797   \n",
      "4  -0.944955  1.000000  0.999967  0.999999  0.999976  0.999536  0.316767   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "95 -0.904201  0.999997  0.999888  0.999996  0.999918  0.998580  0.304325   \n",
      "96  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000 -0.314103   \n",
      "97 -0.795170  0.999990  0.999700  0.999981  0.999726  0.995205  0.215226   \n",
      "98 -0.419752  0.999992  0.999443  0.999966  0.999584  0.992947  0.074180   \n",
      "99 -0.602166  0.999991  0.999713  0.999950  0.999529  0.995830  0.221768   \n",
      "\n",
      "          7         8         9         10        11  \n",
      "0   0.160044 -0.333024 -0.233779  0.999973  0.997936  \n",
      "1  -0.317301  0.483755  0.179913  1.000000  1.000000  \n",
      "2   0.166984 -0.321827 -0.246774  0.999965  0.997974  \n",
      "3  -0.320883  0.452466  0.068261  1.000000  0.999999  \n",
      "4   0.176508 -0.363260 -0.217148  0.999990  0.998024  \n",
      "..       ...       ...       ...       ...       ...  \n",
      "95  0.138398 -0.306879 -0.208785  0.999962  0.994640  \n",
      "96 -0.207615  0.508172  0.125857  1.000000  1.000000  \n",
      "97  0.025075 -0.260997 -0.170363  0.999851  0.986991  \n",
      "98  0.011003 -0.125376 -0.120930  0.999644  0.980136  \n",
      "99  0.039434 -0.236787 -0.186832  0.999790  0.986659  \n",
      "\n",
      "[100 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "noise_vector_size = 100\n",
    "batch_size = 100  \n",
    "\n",
    "noise = torch.randn(batch_size, noise_vector_size, device=device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_data,_ = generator(noise)\n",
    "    \n",
    "df_generated = pd.DataFrame(generated_data.cpu().numpy())\n",
    "print(df_generated.head(100))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Source_X  Source_Y  Destination_X  Destination_Y  Current_X  Current_Y  \\\n",
      "0          0         4              4              4          4          4   \n",
      "1          0         0              0              0          0          0   \n",
      "2          0         4              4              4          4          4   \n",
      "3          4         0              4              0          4          4   \n",
      "4          0         4              4              4          4          4   \n",
      "5          4         0              0              0          0          0   \n",
      "6          0         4              4              4          4          4   \n",
      "7          0         0              0              0          0          0   \n",
      "8          0         4              4              4          4          4   \n",
      "9          0         4              4              4          4          4   \n",
      "10         0         4              4              4          4          4   \n",
      "11         4         0              0              0          0          0   \n",
      "12         0         4              4              4          4          4   \n",
      "13         0         4              4              4          4          4   \n",
      "14         4         4              4              4          4          4   \n",
      "15         0         4              4              4          4          4   \n",
      "16         0         4              4              4          4          4   \n",
      "17         0         0              0              0          0          0   \n",
      "18         4         0              4              4          4          4   \n",
      "19         0         0              0              0          0          0   \n",
      "\n",
      "   Action  Next_X  Next_Y  \n",
      "0      up       4       4  \n",
      "1    down       0       0  \n",
      "2      up       4       4  \n",
      "3    down       4       4  \n",
      "4      up       4       4  \n",
      "5    down       0       0  \n",
      "6      up       4       4  \n",
      "7    down       0       0  \n",
      "8      up       4       4  \n",
      "9      up       4       4  \n",
      "10     up       4       4  \n",
      "11   down       0       0  \n",
      "12     up       4       4  \n",
      "13     up       4       4  \n",
      "14   down       4       4  \n",
      "15     up       4       4  \n",
      "16     up       4       4  \n",
      "17   down       0       0  \n",
      "18   down       4       4  \n",
      "19   down       0       0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def decode_gan_output(gan_output, mesh_size_x, mesh_size_y):\n",
    "    action_mapping = {0: \"up\", 1: \"right\", 2: \"down\", 3: \"left\"}\n",
    "    decoded_data = []\n",
    "    for row in gan_output:\n",
    "        source_x = int((row[0] + 1) * mesh_size_x / 2)%mesh_size_x\n",
    "        source_y = int((row[1] + 1) * mesh_size_y / 2)%mesh_size_y\n",
    "        destination_x = int((row[2] + 1) * mesh_size_x / 2)%mesh_size_x\n",
    "        destination_y = int((row[3] + 1) * mesh_size_y / 2)%mesh_size_y\n",
    "        current_x = int((row[4] + 1) * mesh_size_x / 2)%mesh_size_x\n",
    "        current_y = int((row[5] + 1) * mesh_size_y / 2)%mesh_size_y\n",
    "\n",
    "        action_probs = torch.tensor((row[6:10] + 1) / 2)\n",
    "\n",
    "\n",
    "        action_idx = torch.argmax(action_probs).item()\n",
    "        action = action_mapping[action_idx]\n",
    "        next_x = int((row[10] + 1) * mesh_size_x)%mesh_size_x\n",
    "        next_y = int((row[11] + 1) * mesh_size_y)%mesh_size_y\n",
    "        decoded_data.append([source_x, source_y, destination_x, destination_y, current_x, current_y, action, next_x, next_y])\n",
    "    return pd.DataFrame(decoded_data, columns=['Source_X', 'Source_Y', 'Destination_X', 'Destination_Y', 'Current_X', 'Current_Y', 'Action', 'Next_X', 'Next_Y'])\n",
    "\n",
    "\n",
    "df_generated_values = df_generated.to_numpy()\n",
    "\n",
    "\n",
    "decoded_df = decode_gan_output(df_generated_values, 5, 5)\n",
    "print(decoded_df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting GAN's data to state-action-reward-next-state format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def convert_to_q_learning_format(df, reward_per_step=-1, reward_for_success=10):\n",
    "    q_data = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        state = (row['Current_X'], row['Current_Y'], row['Destination_X'], row['Destination_Y'])\n",
    "        action_map = {'up': 0, 'down': 1, 'left': 2, 'right': 3}\n",
    "        action = action_map[row['Action']]\n",
    "        \n",
    "\n",
    "        if (row['Next_X'], row['Next_Y']) == (row['Destination_X'], row['Destination_Y']):\n",
    "            reward = reward_for_success  \n",
    "        else:\n",
    "            reward = reward_per_step \n",
    "        \n",
    "\n",
    "        next_state = (row['Next_X'], row['Next_Y'], row['Destination_X'], row['Destination_Y'])\n",
    "        \n",
    "        q_data.append((state, action, reward, next_state))\n",
    "    \n",
    "    return q_data\n",
    "\n",
    "\n",
    "df = pd.DataFrame(decoded_df)  \n",
    "q_learning_data = convert_to_q_learning_format(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 4, 4)\n",
      "(5, 5, 5, 5)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 780 is out of bounds for axis 0 with size 625",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m current_q_value \u001b[38;5;241m=\u001b[39m Q_table[state_index, action]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(next_state)\n\u001b[0;32m---> 26\u001b[0m next_max_q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(Q_table[next_state_index])\n\u001b[1;32m     29\u001b[0m new_q_value \u001b[38;5;241m=\u001b[39m current_q_value \u001b[38;5;241m+\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m (reward \u001b[38;5;241m+\u001b[39m discount_factor \u001b[38;5;241m*\u001b[39m next_max_q \u001b[38;5;241m-\u001b[39m current_q_value)\n\u001b[1;32m     30\u001b[0m Q_table[state_index, action] \u001b[38;5;241m=\u001b[39m new_q_value\n",
      "\u001b[0;31mIndexError\u001b[0m: index 780 is out of bounds for axis 0 with size 625"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "m, n = 5, 5 \n",
    "n_actions = 4  \n",
    "learning_rate = 0.1\n",
    "discount_factor = 0.99\n",
    "\n",
    "n_states = m * n * m * n\n",
    "\n",
    "Q_table = np.zeros((n_states, n_actions))\n",
    "\n",
    "def get_state_index(state, m, n):\n",
    "    current_x, current_y, destination_x, destination_y = state\n",
    "    return (current_x * n + current_y) * (m * n) + (destination_x * n + destination_y)\n",
    "\n",
    "\n",
    "q_learning_data = q_learning_data\n",
    "\n",
    "\n",
    "for state, action, reward, next_state in q_learning_data:\n",
    "    state_index = get_state_index(state, m, n)\n",
    "    next_state_index = get_state_index(next_state, m, n)\n",
    "    \n",
    "    current_q_value = Q_table[state_index, action]\n",
    "    print(next_state)\n",
    "    next_max_q = np.max(Q_table[next_state_index])\n",
    "    \n",
    "\n",
    "    new_q_value = current_q_value + learning_rate * (reward + discount_factor * next_max_q - current_q_value)\n",
    "    Q_table[state_index, action] = new_q_value\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Up      Down      Left     Right\n",
      "0   0.028364  0.758772  0.598829  0.974205\n",
      "1   0.166743  0.688909  0.640527  0.975692\n",
      "2   0.202374  0.381874  0.275995  0.940433\n",
      "3   0.765112  0.994133  0.016940  0.383205\n",
      "4   0.340881  0.906992  0.789492  0.928716\n",
      "..       ...       ...       ...       ...\n",
      "95  0.432117  0.384925  0.192939  0.701388\n",
      "96  0.378212  0.060167  0.363165  0.383217\n",
      "97  0.648298  0.772494  0.367362  0.467915\n",
      "98  0.087737  0.730701  0.357271  0.145272\n",
      "99  0.848722  0.908848  0.394579  0.912282\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n_states = 100 \n",
    "n_actions = 4  \n",
    "\n",
    "\n",
    "\n",
    "Q_table_df = pd.DataFrame(Q_table, columns=['Up', 'Down', 'Left', 'Right'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(Q_table_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_index(state, size_x):\n",
    "    x, y = state\n",
    "    return x * size_x + y\n",
    "\n",
    "def index_to_state(index, size_x):\n",
    "    x = index // size_x\n",
    "    y = index % size_x\n",
    "    return (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State (2, 3) corresponds to index 13\n",
      "Index 13 corresponds to state (2, 3)\n"
     ]
    }
   ],
   "source": [
    "size_x = 5  \n",
    "\n",
    "\n",
    "state = (2, 3) \n",
    "index = state_to_index(state, size_x)\n",
    "print(f\"State {state} corresponds to index {index}\")\n",
    "\n",
    "\n",
    "index = 13\n",
    "state = index_to_state(index, size_x)\n",
    "print(f\"Index {index} corresponds to state {state}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal path from (0, 0) to (4, 4): [(0, 0), (0, -1), (0, -2), (0, -1)]\n",
      "Optimal path from (2, 3) to (1, 1): [(2, 3), (1, 3), (1, 2), (0, 2), (0, 1), (0, 0), (0, -1), (0, -2), (0, -1)]\n"
     ]
    }
   ],
   "source": [
    "def get_optimal_path(source, destination, Q_table, state_to_index, index_to_state, size_x):\n",
    "\n",
    "    current_state = source\n",
    "    path = [current_state]\n",
    "\n",
    "    while current_state != destination:\n",
    "        current_index = state_to_index(current_state, size_x)\n",
    "        action = np.argmax(Q_table[current_index])  \n",
    "        \n",
    "\n",
    "        if action == 0:  \n",
    "            next_state = (current_state[0] - 1, current_state[1])\n",
    "        elif action == 1:  \n",
    "            next_state = (current_state[0], current_state[1] + 1)\n",
    "        elif action == 2:  \n",
    "            next_state = (current_state[0] + 1, current_state[1])\n",
    "        else:  \n",
    "            next_state = (current_state[0], current_state[1] - 1)\n",
    "        \n",
    "        path.append(next_state)\n",
    "        current_state = next_state\n",
    "\n",
    "\n",
    "        if len(path) > size_x * size_x or path.count(current_state) > 1:\n",
    "            break\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "test_pairs = [((0, 0), (4, 4)), ((2, 3), (1, 1))]\n",
    "\n",
    "for source, destination in test_pairs:\n",
    "    optimal_path = get_optimal_path(source, destination, Q_table, state_to_index, index_to_state, size_x=5)\n",
    "    print(f\"Optimal path from {source} to {destination}: {optimal_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source index: 0, Destination index: 24\n",
      "Source index: 13, Destination index: 6\n"
     ]
    }
   ],
   "source": [
    "# Example test pairs using coordinates in a 5x5 mesh\n",
    "test_pairs = [\n",
    "    {'source': (0, 0), 'destination': (4, 4)},  # From top-left to bottom-right\n",
    "    {'source': (2, 3), 'destination': (1, 1)},  # From one point to another within the mesh\n",
    "    # Add more pairs as needed\n",
    "]\n",
    "\n",
    "# Convert to your model's input format if necessary\n",
    "# For example, if your model uses flattened indices instead of (x, y) coordinates\n",
    "def convert_coordinates_to_index(x, y, size_x):\n",
    "    return x * size_x + y\n",
    "\n",
    "# Example of converting a test pair to the model's expected input format\n",
    "for pair in test_pairs:\n",
    "    source_index = convert_coordinates_to_index(pair['source'][0], pair['source'][1], size_x=5)\n",
    "    destination_index = convert_coordinates_to_index(pair['destination'][0], pair['destination'][1], size_x=5)\n",
    "    print(f\"Source index: {source_index}, Destination index: {destination_index}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
